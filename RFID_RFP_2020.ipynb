{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "RFID RFP 2020",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2na5SCvgAsXQ"
   },
   "source": [
    "<a href=\"https://github.com/mauropv/RFID-Fingerprint2020/blob/master/RFID_RFP_2020.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# The Tags Are Alright: Robust Large-Scale RFID Clone Detection Through Federated Data-Augmented Radio Fingerprinting  \n",
    "## Authors: Mauro Piva<sup>1</sup>, Gaia Maselli<sup>1</sup>, Francesco Restuccia<sup>2</sup>  \n",
    "### <sup>1</sup>Department of Computer Science, Sapienza University, Italy\n",
    "### <sup>2</sup>Department of Electrical and Computer Engineering, Northeastern University, United States  \n",
    "\n",
    "# Notebook Description\n",
    "\n",
    "  \n",
    "This code is used to demonstrate our recent paper and to offer some example on ho to manage the related dataset.  \n",
    "\n",
    "Please select an environment with a GPU available\n",
    "\n",
    "Open this folder with google drive: https://drive.google.com/drive/folders/1l7cvR1Z8V7eiVdqcPgv0i5rb2ZMSja63?usp=sharing\n",
    "\n",
    "Click on add shortcut to my drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ku0uts1fAqNR",
    "outputId": "028db4f2-8cc9-4ebc-d3e0-797f367fc1d2"
   },
   "source": [
    "#Importing Dataframe\r\n",
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')\r\n",
    "\r\n",
    "\r\n",
    "import os\r\n",
    "PATH_TRAIN = '/content/drive/My Drive/Public-RFID2020-RFP-Dataset/preprocessed/FILT-train/'\r\n",
    "PATH_VALID = '/content/drive/My Drive/Public-RFID2020-RFP-Dataset/preprocessed/FILT-validation/'\r\n",
    "PATH_TEST = \"/content/drive/My Drive/Public-RFID2020-RFP-Dataset/preprocessed/FILT-test/\"\r\n",
    "PATH_MODELS = \"/tmp/\"\r\n",
    "PATH_RESULTS = \"/tmp/\"\r\n",
    "os.path.isdir(PATH_TRAIN)    # False"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQtk9BWnBxLI",
    "outputId": "ac4c2052-0e73-4e0a-95a7-74f1b861bc97"
   },
   "source": [
    "import numpy as np\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "np.set_printoptions(suppress=True)\r\n",
    "np.random.seed(1)\r\n",
    "import torch.optim as optim\r\n",
    "from torchsummary import summary\r\n",
    "import copy\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "print(device)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_RGT0iqeCcy0"
   },
   "source": [
    "#Parameters\r\n",
    "num_tags = 20\r\n",
    "perc_to_load = 0.1\r\n",
    "additive_id = 0\r\n",
    "batch_size = 64"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_02hS25pChmw"
   },
   "source": [
    "def load_data_split(root_path, start, end, first_id, last_id, letts,additive_id):\r\n",
    "    wave_piece_size = 1024#3072# 1024\r\n",
    "    X, y = [], []\r\n",
    "    for raw_signal_file in os.listdir(root_path):\r\n",
    "        \r\n",
    "        tag_id = raw_signal_file[5:8]\r\n",
    "        tag_let = raw_signal_file[8]\r\n",
    "        if (tag_let not in letts or first_id > int(tag_id) or last_id <= int(tag_id)):\r\n",
    "            continue\r\n",
    "        print(raw_signal_file)\r\n",
    "        signal_loaded = np.load(open(root_path + raw_signal_file, \"rb\"))\r\n",
    "        for wave_id in range(int(len(signal_loaded) * start), int(len(signal_loaded) * end)):\r\n",
    "            wave = signal_loaded[wave_id]\r\n",
    "            for i in range(0, len(wave) - wave_piece_size, 256):\r\n",
    "                x_tmp = np.asarray(wave[i:i + wave_piece_size])\r\n",
    "                X += [x_tmp]\r\n",
    "                y += [int(tag_id)-additive_id]\r\n",
    "    return X, y"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33je9D3UCmwo",
    "outputId": "b52012cd-2f17-4ee9-922e-e361ebb4684c"
   },
   "source": [
    "kernel_size = 3\r\n",
    "\r\n",
    "a0 = nn.Conv1d(in_channels= 2, out_channels= 25, kernel_size= 3, padding = (kernel_size // 2))\r\n",
    "a1 = nn.LeakyReLU(negative_slope=0.1)\r\n",
    "b0 = nn.MaxPool1d(kernel_size = 2, padding = 1)\r\n",
    "\r\n",
    "c0 = nn.Conv1d(in_channels= 25, out_channels= 25, kernel_size= 3, padding = (kernel_size // 2))\r\n",
    "c1 = nn.LeakyReLU(negative_slope=0.1)\r\n",
    "d0 = nn.MaxPool1d(2, padding = 1)\r\n",
    "\r\n",
    "e0 = nn.Flatten()   \r\n",
    "e1 = nn.Linear(6425,num_tags)\r\n",
    "\r\n",
    "model = nn.Sequential(a0,a1,b0,c0,c1,d0,e0,e1)\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "def accuracy(predictions, labels):\r\n",
    "    classes = torch.argmax(predictions, dim=1)\r\n",
    "    return torch.mean((classes == labels).float())\r\n",
    "\r\n",
    "summary(model.cuda(),(2,1024))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 25, 1024]             175\n",
      "         LeakyReLU-2             [-1, 25, 1024]               0\n",
      "         MaxPool1d-3              [-1, 25, 513]               0\n",
      "            Conv1d-4              [-1, 25, 513]           1,900\n",
      "         LeakyReLU-5              [-1, 25, 513]               0\n",
      "         MaxPool1d-6              [-1, 25, 257]               0\n",
      "           Flatten-7                 [-1, 6425]               0\n",
      "            Linear-8                   [-1, 20]         128,520\n",
      "================================================================\n",
      "Total params: 130,595\n",
      "Trainable params: 130,595\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.78\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 1.29\n",
      "----------------------------------------------------------------\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6AVQ7MdJCz4x"
   },
   "source": [
    "def client_update(client_model, optimizer, train_loader, epoch):\r\n",
    "    \"\"\"\r\n",
    "    This function updates/trains client model on client data\r\n",
    "    \"\"\"\r\n",
    "    client_model.train()\r\n",
    "    accs = []\r\n",
    "    for e in range(epoch):\r\n",
    "        running_accuracy = 0.\r\n",
    "        l = len((train_loader))\r\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\r\n",
    "            #print(batch_idx, l)\r\n",
    "            #data, target = augment(data, target)\r\n",
    "            data, target = data.cuda(), target.cuda()\r\n",
    "            optimizer.zero_grad()\r\n",
    "\r\n",
    "            output = client_model(data)\r\n",
    "            loss = criterion(output, target.long())\r\n",
    "\r\n",
    "            #loss = F.nll_loss(output, target.long())\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            running_accuracy += accuracy(output, target)/len(train_loader)\r\n",
    "        print(str(running_accuracy.cpu().numpy()))\r\n",
    "        accs.append(running_accuracy.cpu().numpy())\r\n",
    "        #print(accs)\r\n",
    "\r\n",
    "    return loss.item(), accs\r\n",
    "\r\n",
    "def server_aggregate(global_model, client_models):\r\n",
    "    \"\"\"\r\n",
    "    This function has aggregation method 'mean'\r\n",
    "    \"\"\"\r\n",
    "    ### This will take simple mean of the weights of models ###\r\n",
    "    global_dict = global_model.state_dict()\r\n",
    "    for k in global_dict.keys():\r\n",
    "      global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\r\n",
    "    global_model.load_state_dict(global_dict)\r\n",
    "    for m in client_models:\r\n",
    "      m.load_state_dict(global_model.state_dict())\r\n",
    "    \r\n",
    "def test(testing_model, testing_loader):\r\n",
    "    \r\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\r\n",
    "    testing_model.eval()\r\n",
    "    test_loss = 0\r\n",
    "    correct = 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for data, target in testing_loader:\r\n",
    "            data, target = data.cuda(), target.cuda()#data, target#data.cuda(), target.cuda()\r\n",
    "            output = testing_model(data)\r\n",
    "            test_loss += F.nll_loss(output, target.long(), reduction='sum').item()  # sum up batch loss\r\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\r\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\r\n",
    "\r\n",
    "    test_loss /= len(testing_loader.dataset)\r\n",
    "    acc = correct / len(testing_loader.dataset)\r\n",
    "    del testing_model\r\n",
    "\r\n",
    "    return test_loss, acc"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mzOk1_9BEOgd"
   },
   "source": [
    "def augment(data, target):\r\n",
    "    pitch = [5,10,20,100]\r\n",
    "    data_ret, target_ret = data.clone(), target.clone()\r\n",
    "    means = data.mean(axis = 2)\r\n",
    "    for p in pitch:\r\n",
    "        gc.collect()\r\n",
    "        dr,tr = data.clone(), target.clone()\r\n",
    "        i = -1\r\n",
    "        for tensor in dr:\r\n",
    "            i += 1\r\n",
    "            tensor[:,0] = tensor[:,0].add(torch.normal(0, abs(means[i][0]/p), size=(1, data.shape[1])))\r\n",
    "            tensor[:,1] = tensor[:,1].add(torch.normal(0, abs(means[i][1]/p), size=(1, data.shape[1])))\r\n",
    "        data_ret = torch.cat((data_ret, dr), dim = 0)\r\n",
    "        target_ret = torch.cat((target_ret, tr), dim = 0)\r\n",
    "    return data_ret, target_ret"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FjpTCCKZDL-3"
   },
   "source": [
    "# Parameters\r\n",
    "params = {'batch_size': batch_size,\r\n",
    "          'shuffle': True,\r\n",
    "          'num_workers': 4}\r\n",
    "\r\n",
    "def generaTrainSet(lettera):\r\n",
    "    X, y = load_data_split(PATH_TRAIN, 0, perc_to_load, additive_id, additive_id+num_tags, lettera,0)\r\n",
    "    X_train = torch.from_numpy(np.asarray(X)).float()\r\n",
    "    X_train = X_train.transpose(1, 2).contiguous()\r\n",
    "    y_train = torch.from_numpy(np.asarray(y))\r\n",
    "    #X_train, y_train = augment(X_train, y_train)\r\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, y_train)\r\n",
    "    training_generator = torch.utils.data.DataLoader(dataset, **params)\r\n",
    "    return training_generator\r\n",
    "\r\n",
    "train_loader = [generaTrainSet(\"A\"),generaTrainSet(\"B\"),generaTrainSet(\"C\")]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dWWNk7z7DWc0"
   },
   "source": [
    "Xt, yt = load_data_split(PATH_VALID, 0, 1, additive_id, additive_id+num_tags, \"ABC\",0)\r\n",
    "\r\n",
    "\r\n",
    "X_test = torch.from_numpy(np.asarray(Xt)).float()\r\n",
    "X_test = X_test.transpose(1, 2).contiguous()\r\n",
    "y_test = torch.from_numpy(np.asarray(yt))\r\n",
    "dataset_t = torch.utils.data.TensorDataset(X_test, y_test)\r\n",
    "\r\n",
    "\r\n",
    "# Parameters\r\n",
    "params = {'batch_size': batch_size,\r\n",
    "          'shuffle': True}\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "test_generator = torch.utils.data.DataLoader(dataset_t, **params)\r\n",
    "test_loader = test_generator"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o_-6DyQxDqpP"
   },
   "source": [
    "num_clients = 3\r\n",
    "num_selected =3\r\n",
    "num_rounds = 100\r\n",
    "epochs = 1\r\n",
    "\r\n",
    "global_model =  copy.deepcopy(model).cuda()\r\n",
    "\r\n",
    "client_models = [ copy.deepcopy(model).cuda() for _ in range(num_selected)]\r\n",
    "for model in client_models:\r\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \r\n",
    "\r\n",
    "opt = [optim.Adam(model.parameters()) for model in client_models]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Toar2uArDyal",
    "outputId": "8b86db89-37ac-450d-bb7e-785327c97eb5"
   },
   "source": [
    "losses_train = []\r\n",
    "losses_test = []\r\n",
    "acc_train = []\r\n",
    "acc_test = []\r\n",
    "\r\n",
    "accs_tot = [[],[],[]]\r\n",
    "\r\n",
    "for r in range(num_rounds):\r\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\r\n",
    "    loss = 0\r\n",
    "    for i in range(num_selected):\r\n",
    "        print(\"CLI\",client_idx[i])\r\n",
    "        l, accs = client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\r\n",
    "        loss += l\r\n",
    "        for a in accs:\r\n",
    "            accs_tot[client_idx[i]].append(a)\r\n",
    " \r\n",
    "    losses_train.append(loss)\r\n",
    "    server_aggregate(global_model, client_models)\r\n",
    "    test_loss, acc = test(global_model, test_loader)\r\n",
    "    losses_test.append(test_loss)\r\n",
    "    acc_test.append(acc)\r\n",
    "    print('%d-th round' % r)\r\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\r\n",
    "\r\n",
    "#print(accs_tot)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "CLI 0\n",
      "0.99016565\n",
      "CLI 2\n",
      "0.9611273\n",
      "CLI 1\n",
      "0.9873359\n",
      "0-th round\n",
      "average train loss 30.2 | test loss 320 | test acc: 0.561\n",
      "CLI 2\n",
      "0.9572907\n",
      "CLI 1\n",
      "0.98544306\n",
      "CLI 0\n",
      "0.9864729\n",
      "1-th round\n",
      "average train loss 43.7 | test loss -396 | test acc: 0.559\n",
      "CLI 2\n",
      "0.96430755\n",
      "CLI 1\n",
      "0.984703\n",
      "CLI 0\n",
      "0.99312747\n",
      "2-th round\n",
      "average train loss 0 | test loss -113 | test acc: 0.563\n",
      "CLI 2\n",
      "0.95794624\n",
      "CLI 1\n",
      "0.9888178\n",
      "CLI 0\n",
      "0.9881194\n",
      "3-th round\n",
      "average train loss 0 | test loss 1.31e+03 | test acc: 0.526\n",
      "CLI 0\n",
      "0.9915831\n",
      "CLI 2\n",
      "0.94913715\n",
      "CLI 1\n",
      "0.9831717\n",
      "4-th round\n",
      "average train loss 7.05 | test loss 636 | test acc: 0.562\n",
      "CLI 2\n",
      "0.9468908\n",
      "CLI 0\n",
      "0.99064875\n",
      "CLI 1\n",
      "0.9890199\n",
      "5-th round\n",
      "average train loss 0 | test loss 933 | test acc: 0.611\n",
      "CLI 0\n",
      "0.99166006\n",
      "CLI 1\n",
      "0.98242235\n",
      "CLI 2\n",
      "0.95303595\n",
      "6-th round\n",
      "average train loss 76.3 | test loss 749 | test acc: 0.612\n",
      "CLI 1\n",
      "0.9844249\n",
      "CLI 2\n",
      "0.95317525\n",
      "CLI 0\n",
      "0.9913825\n",
      "7-th round\n",
      "average train loss 0 | test loss 773 | test acc: 0.567\n",
      "CLI 0\n",
      "0.9886245\n",
      "CLI 1\n",
      "0.98513144\n",
      "CLI 2\n",
      "0.9444781\n",
      "8-th round\n",
      "average train loss 80.1 | test loss 237 | test acc: 0.614\n",
      "CLI 1\n",
      "0.985259\n",
      "CLI 2\n",
      "0.9600385\n",
      "CLI 0\n",
      "0.99186295\n",
      "9-th round\n",
      "average train loss 98.6 | test loss 886 | test acc: 0.597\n",
      "CLI 1\n",
      "0.98755467\n",
      "CLI 0\n",
      "0.9914322\n",
      "CLI 2\n",
      "0.96354944\n",
      "10-th round\n",
      "average train loss 0 | test loss 52.8 | test acc: 0.616\n",
      "CLI 2\n",
      "0.95463896\n",
      "CLI 1\n",
      "0.98450106\n",
      "CLI 0\n",
      "0.99135494\n",
      "11-th round\n",
      "average train loss 5.61 | test loss 452 | test acc: 0.584\n",
      "CLI 0\n",
      "0.99140704\n",
      "CLI 2\n",
      "0.9592198\n",
      "CLI 1\n",
      "0.9839282\n",
      "12-th round\n",
      "average train loss 80.4 | test loss 254 | test acc: 0.593\n",
      "CLI 2\n",
      "0.9566563\n",
      "CLI 0\n",
      "0.990369\n",
      "CLI 1\n",
      "0.9895997\n",
      "13-th round\n",
      "average train loss 21.7 | test loss 1.09e+03 | test acc: 0.605\n",
      "CLI 2\n",
      "0.96498805\n",
      "CLI 1\n",
      "0.98715913\n",
      "CLI 0\n",
      "0.9858433\n",
      "14-th round\n",
      "average train loss 25.1 | test loss 126 | test acc: 0.569\n",
      "CLI 1\n",
      "0.9838266\n",
      "CLI 2\n",
      "0.9573768\n",
      "CLI 0\n",
      "0.99542797\n",
      "15-th round\n",
      "average train loss 37.4 | test loss -182 | test acc: 0.602\n",
      "CLI 2\n",
      "0.95857775\n",
      "CLI 1\n",
      "0.9867309\n",
      "CLI 0\n",
      "0.98930806\n",
      "16-th round\n",
      "average train loss 6.23 | test loss 457 | test acc: 0.578\n",
      "CLI 2\n",
      "0.97024983\n",
      "CLI 1\n",
      "0.9877825\n",
      "CLI 0\n",
      "0.98880047\n",
      "17-th round\n",
      "average train loss 44.4 | test loss 311 | test acc: 0.586\n",
      "CLI 0\n",
      "0.9889533\n",
      "CLI 1\n",
      "0.9895748\n",
      "CLI 2\n",
      "0.9471043\n",
      "18-th round\n",
      "average train loss 42 | test loss 128 | test acc: 0.588\n",
      "CLI 1\n",
      "0.98356724\n",
      "CLI 2\n",
      "0.95312506\n",
      "CLI 0\n",
      "0.9949232\n",
      "19-th round\n",
      "average train loss 0 | test loss -586 | test acc: 0.573\n",
      "CLI 1\n",
      "0.99232674\n",
      "CLI 0\n",
      "0.99014217\n",
      "CLI 2\n",
      "0.9601933\n",
      "20-th round\n",
      "average train loss 14.5 | test loss 1e+03 | test acc: 0.604\n",
      "CLI 0\n",
      "0.9895872\n",
      "CLI 2\n",
      "0.9646605\n",
      "CLI 1\n",
      "0.98563707\n",
      "21-th round\n",
      "average train loss 0 | test loss -13.8 | test acc: 0.595\n",
      "CLI 1\n",
      "0.9851577\n",
      "CLI 2\n",
      "0.96597314\n",
      "CLI 0\n",
      "0.99029386\n",
      "22-th round\n",
      "average train loss 7.1 | test loss 423 | test acc: 0.644\n",
      "CLI 2\n",
      "0.96090025\n",
      "CLI 1\n",
      "0.98369294\n",
      "CLI 0\n",
      "0.992368\n",
      "23-th round\n",
      "average train loss 0 | test loss 812 | test acc: 0.636\n",
      "CLI 0\n",
      "0.9916076\n",
      "CLI 1\n",
      "0.99049985\n",
      "CLI 2\n",
      "0.95577526\n",
      "24-th round\n",
      "average train loss 30.3 | test loss 25.8 | test acc: 0.628\n",
      "CLI 2\n",
      "0.95866185\n",
      "CLI 0\n",
      "0.9885985\n",
      "CLI 1\n",
      "0.98707676\n",
      "25-th round\n",
      "average train loss 31.5 | test loss 576 | test acc: 0.612\n",
      "CLI 2\n",
      "0.9671708\n",
      "CLI 1\n",
      "0.9880856\n",
      "CLI 0\n",
      "0.9931521\n",
      "26-th round\n",
      "average train loss 1.69 | test loss 367 | test acc: 0.623\n",
      "CLI 2\n",
      "0.9643582\n",
      "CLI 1\n",
      "0.9868057\n",
      "CLI 0\n",
      "0.9909269\n",
      "27-th round\n",
      "average train loss 6.2 | test loss 726 | test acc: 0.607\n",
      "CLI 1\n",
      "0.98747975\n",
      "CLI 0\n",
      "0.9927474\n",
      "CLI 2\n",
      "0.9580837\n",
      "28-th round\n",
      "average train loss 28.3 | test loss 1.27e+03 | test acc: 0.596\n",
      "CLI 2\n",
      "0.96102655\n",
      "CLI 1\n",
      "0.9860987\n",
      "CLI 0\n",
      "0.9905968\n",
      "29-th round\n",
      "average train loss 24.1 | test loss 1.03e+03 | test acc: 0.628\n",
      "CLI 0\n",
      "0.9899136\n",
      "CLI 1\n",
      "0.98904514\n",
      "CLI 2\n",
      "0.96513784\n",
      "30-th round\n",
      "average train loss 53.2 | test loss 526 | test acc: 0.638\n",
      "CLI 0\n",
      "0.99034476\n",
      "CLI 1\n",
      "0.9892547\n",
      "CLI 2\n",
      "0.9648987\n",
      "31-th round\n",
      "average train loss 12.4 | test loss 1.71e+03 | test acc: 0.607\n",
      "CLI 0\n",
      "0.99322754\n",
      "CLI 1\n",
      "0.9885653\n",
      "CLI 2\n",
      "0.96921504\n",
      "32-th round\n",
      "average train loss 3.51 | test loss 2.28e+03 | test acc: 0.589\n",
      "CLI 0\n",
      "0.9901669\n",
      "CLI 1\n",
      "0.98725265\n",
      "CLI 2\n",
      "0.9683573\n",
      "33-th round\n",
      "average train loss 11.4 | test loss 2.22e+03 | test acc: 0.568\n",
      "CLI 0\n",
      "0.9922423\n",
      "CLI 2\n",
      "0.9586245\n",
      "CLI 1\n",
      "0.98692477\n",
      "34-th round\n",
      "average train loss 44.9 | test loss 2.2e+03 | test acc: 0.623\n",
      "CLI 1\n",
      "0.98384523\n",
      "CLI 0\n",
      "0.9921154\n",
      "CLI 2\n",
      "0.96463585\n",
      "35-th round\n",
      "average train loss 0 | test loss 2.59e+03 | test acc: 0.618\n",
      "CLI 1\n",
      "0.9904591\n",
      "CLI 0\n",
      "0.99107695\n",
      "CLI 2\n",
      "0.9709961\n",
      "36-th round\n",
      "average train loss 0 | test loss 3.27e+03 | test acc: 0.596\n",
      "CLI 1\n",
      "0.9887923\n",
      "CLI 2\n",
      "0.9542582\n",
      "CLI 0\n",
      "0.99064684\n",
      "37-th round\n",
      "average train loss 29.4 | test loss 2.71e+03 | test acc: 0.642\n",
      "CLI 2\n",
      "0.960976\n",
      "CLI 1\n",
      "0.9896003\n",
      "CLI 0\n",
      "0.9894844\n",
      "38-th round\n",
      "average train loss 0 | test loss 3.17e+03 | test acc: 0.606\n",
      "CLI 2\n",
      "0.9655941\n",
      "CLI 0\n",
      "0.99299777\n",
      "CLI 1\n",
      "0.98806125\n",
      "39-th round\n",
      "average train loss 8.94 | test loss 1.89e+03 | test acc: 0.621\n",
      "CLI 0\n",
      "0.9918108\n",
      "CLI 1\n",
      "0.9900298\n",
      "CLI 2\n",
      "0.9651913\n",
      "40-th round\n",
      "average train loss 0 | test loss 3.1e+03 | test acc: 0.622\n",
      "CLI 0\n",
      "0.9924171\n",
      "CLI 2\n",
      "0.95596397\n",
      "CLI 1\n",
      "0.98980266\n",
      "41-th round\n",
      "average train loss 1.28 | test loss 1.63e+03 | test acc: 0.642\n",
      "CLI 0\n",
      "0.98908\n",
      "CLI 2\n",
      "0.97411233\n",
      "CLI 1\n",
      "0.9890195\n",
      "42-th round\n",
      "average train loss 3.82 | test loss 3.31e+03 | test acc: 0.614\n",
      "CLI 1\n",
      "0.9863443\n",
      "CLI 2\n",
      "0.9624755\n",
      "CLI 0\n",
      "0.99272\n",
      "43-th round\n",
      "average train loss 17.9 | test loss 3.52e+03 | test acc: 0.644\n",
      "CLI 1\n",
      "0.98970926\n",
      "CLI 0\n",
      "0.9898144\n",
      "CLI 2\n",
      "0.95941067\n",
      "44-th round\n",
      "average train loss 6.55 | test loss 2.68e+03 | test acc: 0.631\n",
      "CLI 1\n",
      "0.9875052\n",
      "CLI 2\n",
      "0.9724855\n",
      "CLI 0\n",
      "0.99449134\n",
      "45-th round\n",
      "average train loss 2.89 | test loss 2.72e+03 | test acc: 0.658\n",
      "CLI 0\n",
      "0.99115485\n",
      "CLI 1\n",
      "0.9860657\n",
      "CLI 2\n",
      "0.9595484\n",
      "46-th round\n",
      "average train loss 11.7 | test loss 3.58e+03 | test acc: 0.595\n",
      "CLI 1\n",
      "0.9886497\n",
      "CLI 2\n",
      "0.971652\n",
      "CLI 0\n",
      "0.99216485\n",
      "47-th round\n",
      "average train loss 3.83 | test loss 3.13e+03 | test acc: 0.630\n",
      "CLI 1\n",
      "0.99195606\n",
      "CLI 2\n",
      "0.97274876\n",
      "CLI 0\n",
      "0.9903709\n",
      "48-th round\n",
      "average train loss 18.4 | test loss 2.95e+03 | test acc: 0.612\n",
      "CLI 0\n",
      "0.98986405\n",
      "CLI 1\n",
      "0.9881109\n",
      "CLI 2\n",
      "0.9667304\n",
      "49-th round\n",
      "average train loss 0 | test loss 3.47e+03 | test acc: 0.622\n",
      "CLI 2\n",
      "0.96498907\n",
      "CLI 0\n",
      "0.99077624\n",
      "CLI 1\n",
      "0.9892215\n",
      "50-th round\n",
      "average train loss 0 | test loss 1.17e+03 | test acc: 0.660\n",
      "CLI 1\n",
      "0.9887667\n",
      "CLI 0\n",
      "0.99289876\n",
      "CLI 2\n",
      "0.96445805\n",
      "51-th round\n",
      "average train loss 1.62 | test loss 3.81e+03 | test acc: 0.622\n",
      "CLI 2\n",
      "0.9668058\n",
      "CLI 0\n",
      "0.9927729\n",
      "CLI 1\n",
      "0.98929733\n",
      "52-th round\n",
      "average train loss 0 | test loss 2.06e+03 | test acc: 0.645\n",
      "CLI 2\n",
      "0.97162485\n",
      "CLI 0\n",
      "0.9920659\n",
      "CLI 1\n",
      "0.99213296\n",
      "53-th round\n",
      "average train loss 87.9 | test loss 2.77e+03 | test acc: 0.616\n",
      "CLI 2\n",
      "0.9718542\n",
      "CLI 0\n",
      "0.9923425\n",
      "CLI 1\n",
      "0.99159443\n",
      "54-th round\n",
      "average train loss 0 | test loss 2.7e+03 | test acc: 0.624\n",
      "CLI 1\n",
      "0.98844695\n",
      "CLI 2\n",
      "0.9597746\n",
      "CLI 0\n",
      "0.9887763\n",
      "55-th round\n",
      "average train loss 10.5 | test loss 4.59e+03 | test acc: 0.621\n",
      "CLI 1\n",
      "0.98922193\n",
      "CLI 0\n",
      "0.9926218\n",
      "CLI 2\n",
      "0.9618839\n",
      "56-th round\n",
      "average train loss 0 | test loss 3.26e+03 | test acc: 0.643\n",
      "CLI 2\n",
      "0.9676248\n",
      "CLI 1\n",
      "0.9876311\n",
      "CLI 0\n",
      "0.9956046\n",
      "57-th round\n",
      "average train loss 26.6 | test loss 2.56e+03 | test acc: 0.640\n",
      "CLI 1\n",
      "0.98937297\n",
      "CLI 0\n",
      "0.9913555\n",
      "CLI 2\n",
      "0.96761405\n",
      "58-th round\n",
      "average train loss 1.67 | test loss 4.17e+03 | test acc: 0.621\n",
      "CLI 0\n",
      "0.9927974\n",
      "CLI 1\n",
      "0.9898179\n",
      "CLI 2\n",
      "0.97085553\n",
      "59-th round\n",
      "average train loss 87.4 | test loss 4.19e+03 | test acc: 0.648\n",
      "CLI 2\n",
      "0.9639654\n",
      "CLI 1\n",
      "0.9903329\n",
      "CLI 0\n",
      "0.9924179\n",
      "60-th round\n",
      "average train loss 8.05 | test loss 2.66e+03 | test acc: 0.638\n",
      "CLI 2\n",
      "0.9743535\n",
      "CLI 0\n",
      "0.9923664\n",
      "CLI 1\n",
      "0.98798484\n",
      "61-th round\n",
      "average train loss 0 | test loss 3.95e+03 | test acc: 0.619\n",
      "CLI 2\n",
      "0.97155154\n",
      "CLI 1\n",
      "0.9885151\n",
      "CLI 0\n",
      "0.99358004\n",
      "62-th round\n",
      "average train loss 19.4 | test loss 4.41e+03 | test acc: 0.633\n",
      "CLI 0\n",
      "0.9914065\n",
      "CLI 1\n",
      "0.99179715\n",
      "CLI 2\n",
      "0.9653531\n",
      "63-th round\n",
      "average train loss 23.7 | test loss 4.13e+03 | test acc: 0.622\n",
      "CLI 2\n",
      "0.96676683\n",
      "CLI 1\n",
      "0.98967636\n",
      "CLI 0\n",
      "0.99363184\n",
      "64-th round\n",
      "average train loss 39.4 | test loss 3.03e+03 | test acc: 0.664\n",
      "CLI 0\n",
      "0.99423915\n",
      "CLI 1\n",
      "0.99296576\n",
      "CLI 2\n",
      "0.96859795\n",
      "65-th round\n",
      "average train loss 32.4 | test loss 3.88e+03 | test acc: 0.632\n",
      "CLI 2\n",
      "0.96810585\n",
      "CLI 0\n",
      "0.9915335\n",
      "CLI 1\n",
      "0.9886159\n",
      "66-th round\n",
      "average train loss 39.6 | test loss 4.83e+03 | test acc: 0.654\n",
      "CLI 2\n",
      "0.9714512\n",
      "CLI 1\n",
      "0.98972666\n",
      "CLI 0\n",
      "0.9940371\n",
      "67-th round\n",
      "average train loss 0 | test loss 5.07e+03 | test acc: 0.640\n",
      "CLI 1\n",
      "0.99038315\n",
      "CLI 2\n",
      "0.965822\n",
      "CLI 0\n",
      "0.9917096\n",
      "68-th round\n",
      "average train loss 0 | test loss 4.53e+03 | test acc: 0.623\n",
      "CLI 1\n",
      "0.989449\n",
      "CLI 2\n",
      "0.9737981\n",
      "CLI 0\n",
      "0.99494654\n",
      "69-th round\n",
      "average train loss 3.22 | test loss 6.36e+03 | test acc: 0.647\n",
      "CLI 0\n",
      "0.99340546\n",
      "CLI 1\n",
      "0.99076146\n",
      "CLI 2\n",
      "0.96328336\n",
      "70-th round\n",
      "average train loss 10.5 | test loss 6.99e+03 | test acc: 0.659\n",
      "CLI 1\n",
      "0.9882701\n",
      "CLI 2\n",
      "0.96599865\n",
      "CLI 0\n",
      "0.9941884\n",
      "71-th round\n",
      "average train loss 8.45 | test loss 4.26e+03 | test acc: 0.635\n",
      "CLI 0\n",
      "0.9931275\n",
      "CLI 2\n",
      "0.9760552\n",
      "CLI 1\n",
      "0.98938125\n",
      "72-th round\n",
      "average train loss 33.1 | test loss 5.89e+03 | test acc: 0.642\n",
      "CLI 0\n",
      "0.99216574\n",
      "CLI 2\n",
      "0.974653\n",
      "CLI 1\n",
      "0.9899787\n",
      "73-th round\n",
      "average train loss 7.83 | test loss 5.34e+03 | test acc: 0.635\n",
      "CLI 2\n",
      "0.965771\n",
      "CLI 1\n",
      "0.98866665\n",
      "CLI 0\n",
      "0.99325264\n",
      "74-th round\n",
      "average train loss 0 | test loss 5.71e+03 | test acc: 0.629\n",
      "CLI 0\n",
      "0.9911549\n",
      "CLI 1\n",
      "0.9927561\n",
      "CLI 2\n",
      "0.96599865\n",
      "75-th round\n",
      "average train loss 0 | test loss 6.93e+03 | test acc: 0.632\n",
      "CLI 1\n",
      "0.99034065\n",
      "CLI 0\n",
      "0.99090147\n",
      "CLI 2\n",
      "0.9742021\n",
      "76-th round\n",
      "average train loss 31.8 | test loss 5.68e+03 | test acc: 0.662\n",
      "CLI 2\n",
      "0.9696838\n",
      "CLI 0\n",
      "0.99297357\n",
      "CLI 1\n",
      "0.9905426\n",
      "77-th round\n",
      "average train loss 5.46 | test loss 5.21e+03 | test acc: 0.655\n",
      "CLI 2\n",
      "0.97518605\n",
      "CLI 0\n",
      "0.99530214\n",
      "CLI 1\n",
      "0.991545\n",
      "78-th round\n",
      "average train loss 0 | test loss 6.45e+03 | test acc: 0.666\n",
      "CLI 1\n",
      "0.9904086\n",
      "CLI 0\n",
      "0.99145633\n",
      "CLI 2\n",
      "0.968685\n",
      "79-th round\n",
      "average train loss 10.9 | test loss 7.54e+03 | test acc: 0.659\n",
      "CLI 1\n",
      "0.9913002\n",
      "CLI 2\n",
      "0.96579677\n",
      "CLI 0\n",
      "0.9932781\n",
      "80-th round\n",
      "average train loss 27.4 | test loss 6.69e+03 | test acc: 0.667\n",
      "CLI 1\n",
      "0.9909132\n",
      "CLI 0\n",
      "0.99426377\n",
      "CLI 2\n",
      "0.9710721\n",
      "81-th round\n",
      "average train loss 8.61 | test loss 6.19e+03 | test acc: 0.624\n",
      "CLI 0\n",
      "0.993102\n",
      "CLI 2\n",
      "0.9676641\n",
      "CLI 1\n",
      "0.98980236\n",
      "82-th round\n",
      "average train loss 0 | test loss 3.72e+03 | test acc: 0.639\n",
      "CLI 1\n",
      "0.99076146\n",
      "CLI 2\n",
      "0.9769284\n",
      "CLI 0\n",
      "0.9939364\n",
      "83-th round\n",
      "average train loss 0 | test loss 6.44e+03 | test acc: 0.655\n",
      "CLI 0\n",
      "0.9917602\n",
      "CLI 1\n",
      "0.98890156\n",
      "CLI 2\n",
      "0.9698345\n",
      "84-th round\n",
      "average train loss 42.5 | test loss 6.99e+03 | test acc: 0.641\n",
      "CLI 2\n",
      "0.9646472\n",
      "CLI 1\n",
      "0.99033266\n",
      "CLI 0\n",
      "0.9921391\n",
      "85-th round\n",
      "average train loss 69.7 | test loss 6.27e+03 | test acc: 0.682\n",
      "CLI 2\n",
      "0.98018396\n",
      "CLI 0\n",
      "0.9946706\n",
      "CLI 1\n",
      "0.9902563\n",
      "86-th round\n",
      "average train loss 0 | test loss 5.1e+03 | test acc: 0.627\n",
      "CLI 0\n",
      "0.9941377\n",
      "CLI 2\n",
      "0.9688253\n",
      "CLI 1\n",
      "0.99043393\n",
      "87-th round\n",
      "average train loss 0 | test loss 5.89e+03 | test acc: 0.653\n",
      "CLI 1\n",
      "0.9888183\n",
      "CLI 0\n",
      "0.9921916\n",
      "CLI 2\n",
      "0.974\n",
      "88-th round\n",
      "average train loss 0 | test loss 4.66e+03 | test acc: 0.639\n",
      "CLI 0\n",
      "0.9933288\n",
      "CLI 2\n",
      "0.97028935\n",
      "CLI 1\n",
      "0.9926801\n",
      "89-th round\n",
      "average train loss 0 | test loss 5.98e+03 | test acc: 0.656\n",
      "CLI 2\n",
      "0.9700731\n",
      "CLI 1\n",
      "0.9901139\n",
      "CLI 0\n",
      "0.9920631\n",
      "90-th round\n",
      "average train loss 16 | test loss 4.33e+03 | test acc: 0.664\n",
      "CLI 2\n",
      "0.97592926\n",
      "CLI 0\n",
      "0.994215\n",
      "CLI 1\n",
      "0.9909461\n",
      "91-th round\n",
      "average train loss 21.5 | test loss 6.2e+03 | test acc: 0.650\n",
      "CLI 1\n",
      "0.98976\n",
      "CLI 0\n",
      "0.99471945\n",
      "CLI 2\n",
      "0.9675715\n",
      "92-th round\n",
      "average train loss 81.3 | test loss 5.04e+03 | test acc: 0.665\n",
      "CLI 1\n",
      "0.9936904\n",
      "CLI 0\n",
      "0.99360865\n",
      "CLI 2\n",
      "0.9774581\n",
      "93-th round\n",
      "average train loss 0 | test loss 5.19e+03 | test acc: 0.672\n",
      "CLI 0\n",
      "0.9936048\n",
      "CLI 1\n",
      "0.9884898\n",
      "CLI 2\n",
      "0.9769536\n",
      "94-th round\n",
      "average train loss 31 | test loss 5.96e+03 | test acc: 0.669\n",
      "CLI 1\n",
      "0.99141604\n",
      "CLI 2\n",
      "0.9694817\n",
      "CLI 0\n",
      "0.9921902\n",
      "95-th round\n",
      "average train loss 55.6 | test loss 5.69e+03 | test acc: 0.689\n",
      "CLI 1\n",
      "0.9908624\n",
      "CLI 0\n",
      "0.9946183\n",
      "CLI 2\n",
      "0.9738234\n",
      "96-th round\n",
      "average train loss 2.64 | test loss 4.63e+03 | test acc: 0.641\n",
      "CLI 1\n",
      "0.9945991\n",
      "CLI 0\n",
      "0.9935836\n",
      "CLI 2\n",
      "0.9723062\n",
      "97-th round\n",
      "average train loss 20.9 | test loss 7.15e+03 | test acc: 0.654\n",
      "CLI 0\n",
      "0.9935822\n",
      "CLI 1\n",
      "0.9894823\n",
      "CLI 2\n",
      "0.98109347\n",
      "98-th round\n",
      "average train loss 40.8 | test loss 5.33e+03 | test acc: 0.636\n",
      "CLI 2\n",
      "0.9629186\n",
      "CLI 1\n",
      "0.99299073\n",
      "CLI 0\n",
      "0.99368393\n",
      "99-th round\n",
      "average train loss 25 | test loss 7.23e+03 | test acc: 0.602\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3YdjLHjrEf8V",
    "outputId": "27b6b995-4ad5-478d-fad9-4607e9d15729"
   },
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "plt.plot(acc_test)\r\n",
    "plt.ylabel('Test Accuracy')\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5gkKKhlrOipG"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}